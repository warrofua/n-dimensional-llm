# Why N-D (tensor) inputs are necessary for minimum-distortion prediction

Below is a compact, first-principles derivation with the Information Bottleneck (IB) and Rateâ€“Distortion (Râ€“D) lenses. It formalizes your intuition: if reality is multi-field, then projecting to 1-D text imposes an irreducible information deficit for many tasks; synchronized N-D inputs remove that deficit and dominate in Râ€“D.

## 1) Setup

Let the world state be a random object ğ‘Š.

We observe ğ‘€ synchronized fields ğ‘‹â‚:ğ‘€ = (ğ‘‹â‚,â€¦,ğ‘‹ğ‘€) derived from ğ‘Š: e.g., text, 2-D layout, depth, time, gaze, geo, provenance.

A task variable ğ‘Œ (answer, label, program output) depends on ğ‘Š.

An encoder produces a representation ğ‘ = ğœ™(ğ‘‹â‚:ğ‘€) that the decoder uses to predict ğ‘ŒÌ‚.

**Text-only projection.** Many pipelines use a lossy projection ğ‘‹â‚œâ‚‘â‚“â‚œ = ğ‘‡(ğ‘Š) (OCR/string), then ğ‘ = ğœ™â‚œâ‚‘â‚“â‚œ(ğ‘‹â‚œâ‚‘â‚“â‚œ).

We care about two fundamental quantities:

* **Utility:** ğ¼(ğ‘Œ;ğ‘) â€” task-relevant information that survives the bottleneck.
* **Rate:** ğ¼(ğ‘‹â‚:ğ‘€;ğ‘) or a proxy (e.g., number of tokens ğ¾) â€” how much we spend to carry info forward.

## 2) Necessity via mutual information (IB view)

**Proposition 1 (Information deficit of 1-D projection)**

If any field adds task-relevant info beyond text, i.e.

ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) > ğ¼(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ),

then no text-only encoder can match the best N-D encoderâ€™s utility:

maxâ‚ğœ™â‚œâ‚‘â‚“â‚œâ‚ ğ¼(ğ‘Œ;ğœ™â‚œâ‚‘â‚“â‚œ(ğ‘‹â‚œâ‚‘â‚“â‚œ)) â‰¤ ğ¼(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ) < ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) â‰¥ maxâ‚ğœ™â‚ ğ¼(ğ‘Œ;ğœ™(ğ‘‹â‚:ğ‘€)).

*Proof (sketch).* Data processing inequality (DPI): for any mapping ğœ™,

ğ¼(ğ‘Œ;ğœ™(ğ‘‹)) â‰¤ ğ¼(ğ‘Œ;ğ‘‹).

Chain rule gives

ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) = ğ¼(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ) + ğ¼(ğ‘Œ;ğ‘‹Â¬â‚œâ‚‘â‚“â‚œ âˆ£ ğ‘‹â‚œâ‚‘â‚“â‚œ).

If the conditional term > 0, text-only lacks that increment forever. âˆ

**Error bound consequence (Fano).** For discrete ğ‘Œ,

ğ‘ƒâ‚‘ â‰¥ (ğ»(ğ‘Œâˆ£ğ‘) âˆ’ 1)/logâˆ£ğ‘Œâˆ£ â‰¥ (ğ»(ğ‘Œ) âˆ’ ğ¼(ğ‘Œ;ğ‘) âˆ’ 1)/logâˆ£ğ‘Œâˆ£.

Thus a utility gap Î”ğ¼ = ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) âˆ’ ğ¼(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ) > 0 implies a strictly worse lower bound on error for all text-only systems.

*Interpretation.* If layout, time, depth, gaze, geo, provenance, etc. carry any conditionally new information about ğ‘Œ beyond text, then a 1-D pipeline is provably sub-optimal: it cannot reach the Bayes error of an N-D pipeline.

## 3) Dominance at fixed rate (Râ€“D view)

Define the prediction Râ€“D problem with a task distortion ğ‘‘(ğ‘Œ,ğ‘ŒÌ‚):

ğ‘…â‹†(ğ·) = minâ‚ğ‘(ğ‘§âˆ£ğ‘¥)â‚ ğ¼(ğ‘‹;ğ‘)  s.t.  minâ‚ğ‘“â‚ ğ¸[ğ‘‘(ğ‘Œ,ğ‘“(ğ‘))] â‰¤ ğ·.

Compare two feasible sets:

* **Text-only:** ğ‘‹ = ğ‘‹â‚œâ‚‘â‚“â‚œ.
* **N-D tensor:** ğ‘‹ = ğ‘‹â‚:ğ‘€.

**Proposition 2 (Rate advantage with extra fields)**

For any target distortion ğ·,

ğ‘…â‹†_{N-D}(ğ·) â‰¤ ğ‘…â‹†_{text}(ğ·),

with strict inequality whenever the added fields are task-informative:

ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) > ğ¼(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ).

*Proof (sketch).* Any text-only encoder ğ‘(ğ‘§âˆ£ğ‘¥â‚œâ‚‘â‚“â‚œ) is a special case of an N-D encoder that ignores extra fields, so the N-D feasible set is a superset in the Râ€“D program. Strict inclusion + task relevance yields strict improvement. âˆ

Equivalently, at a fixed rate (e.g., token budget ğ¾),

ğ·â‹†_{N-D}(ğ¾) â‰¤ ğ·â‹†_{text}(ğ¾),

with a strict gap under the same condition.

*Interpretation.* With the same number of tokens/compute, the N-D encoder achieves equal or lower distortion; when new fields matter, it is strictly better.

## 4) Why synchronization (tensorization) matters

Extra fields must be co-registered to be useful. Let ğœ™â‚˜: Î©â‚˜ â†’ Î©* map each fieldâ€™s native domain (pixels, time, geo) into a canonical space (e.g., page UV, token spans). Then build tokens

ğ‘â±¼ = ğ‘“ (ğ¸áµ¥áµ¢â‚›(ğ¶â±¼), {pool_{Î¾âˆˆğœ™â‚˜â»Â¹(ğ¶â±¼)} ğ‘”â‚˜(ğ‘‹â‚˜(Î¾)) }â‚˜ ),

over cells ğ¶â±¼ âŠ‚ Î©*.

If ğœ™â‚˜ is inaccurate, you pay a registration penalty:

ğ¼(ğ‘Œ;ğ‘‹â‚:ğ‘€) âˆ’ ğ¼(ğ‘Œ;ğ‘‹Ìƒâ‚:ğ‘€) = lossÂ fromÂ misalignment.

Hence the practical recipe: canonicalize first (e.g., layout coordinates, UV unwarp, time normalization), then compress.

## 5) When does text suffice?

Text-only is optimal iff the new fields are conditionally irrelevant:

ğ¼(ğ‘Œ;ğ‘‹Â¬â‚œâ‚‘â‚“â‚œ âˆ£ ğ‘‹â‚œâ‚‘â‚“â‚œ) = 0.

Examples: pure lexical paraphrase tasks, trivia whose answer is fully in the provided text without spatial/temporal cues. In all other cases (tables, forms, page layout, timelines, diagrams, curved photos, provenance-sensitive QA, salience-sensitive UX), the conditional MI is positive, so N-D is required to reach minimum distortion or minimum error at a fixed rate.

## 6) Practical corollaries (what to build)

* **Variable-rate bottleneck dominates.** Given a fixed token budget ğ¾, learn a selector/router that spends tokens on cells ğ¶â±¼ maximizing an MI proxy with ğ‘Œ. This approximates the IB optimum: maximize ğ¼(ğ‘Œ;ğ‘) subject to âˆ£ğ‘âˆ£ = ğ¾.
* **Fields shift Râ€“D curves down.** Adding synchronized fields (layout, time, depth, gaze, geo, provenance) increases ğ¼(ğ‘Œ;ğ‘‹), so the whole curve ğ·â‹†(ğ¾) moves down (or left in ğ‘…â‹†(ğ·)).
* **Fano sanity check.** Track ğ¼Ì‚(ğ‘Œ;ğ‘) (e.g., InfoNCE proxy) and verify that decreases in CER/WER or EM/F1 track increases in ğ¼Ì‚. If not, your field isnâ€™t aligned or your selector isnâ€™t using it.
* **Square-root heuristic = intuition, not law.** Your â€œ1-D vs 2-D reduces the â€˜unknown manifoldâ€™ from
  ğ‘›
  n to
  ğ‘›
  n
  â€‹â€ is a good mental model of dimensional burden, but the proved quantity is the Î”ğ¼ above. Use the heuristic in prose; optimize Î”ğ¼ in code.

## 7) Minimal proofs-as-algorithms (plug into your stack)

* **Text deficit test.** Estimate Î”ğ¼Ì‚ = ğ¼Ì‚(ğ‘Œ;ğ‘‹â‚:ğ‘€) âˆ’ ğ¼Ì‚(ğ‘Œ;ğ‘‹â‚œâ‚‘â‚“â‚œ) with variational bounds (e.g., MINE/InfoNCE) on held-out data. If Î”ğ¼Ì‚ > 0, route that field into the bottleneck.
* **Râ€“D dominance check.** Sweep token budgets ğ¾ for text-only vs N-D; plot ğ¾ vs distortion. If curves cross only at degenerate tasks, you have empirical Proposition 2.
* **Registration audit.** Measure ğ¼Ì‚(ğ‘Œ;ğ‘‹Ìƒâ‚:ğ‘€) before/after canonicalization ğœ™â‚˜. Gains here directly predict task gains.
